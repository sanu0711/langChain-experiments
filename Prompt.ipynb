{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOQdOB2mhkP/dP96lvKBzZS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanu0711/langChain-experiments/blob/main/Prompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLiqV_T9klgu",
        "outputId": "2c9045e0-9860-4f56-af36-dcf61c23cdbf"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/41.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **üîπ Which One Should You Use?**\n",
        "\n",
        "‚úÖ Use ChatPromptTemplate.from_messages() if you want structured chat conversations with roles.\n",
        "\n",
        "‚úÖ Use ChatPromptTemplate.from_template() if you just need a quick chat prompt.\n",
        "\n",
        "‚úÖ Use PromptTemplate if working with LLMs that don‚Äôt support chat history.\n",
        "\n",
        "‚úÖ Use FewShotPromptTemplate - When you need to provide few-shot learning examples to guide the model.\n",
        "\n",
        "[Docs](https://python.langchain.com/api_reference/core/prompts.html)"
      ],
      "metadata": {
        "id": "UWgnHLiifzG2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Using ChatPromptTemplate.from_template (LangChain Core)\n",
        "\n",
        "* Uses ChatPromptTemplate.from_template() to define a single-turn prompt.\n",
        "\n",
        "* Works best with chat models (like OpenAI's GPT-4).\n",
        "\n",
        "* Simple templating: Uses {product} as a placeholder."
      ],
      "metadata": {
        "id": "Ne8_OkjxdpvW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1Ssp-K-di_l",
        "outputId": "af5560d9-81be-48de-d9e9-8bc64d4fd6d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[HumanMessage(content='What is the best name for a company that makes colorful toy?', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "prompt_template = ChatPromptTemplate.from_template(\n",
        "    \"What is the best name for a company that makes {product}?\"\n",
        ")\n",
        "prompt_template.invoke({\"product\": \"colorful toy\"})\n",
        "# prompt_template.format_prompt(product=\"colorful toy\")\n",
        "# prompt_template.format_prompt(product=\"colorful toy\").to_messages()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Using ChatPromptTemplate.from_messages (Structured Chat Messages)\n",
        "\n",
        "* Defines a multi-turn conversation.\n",
        "\n",
        "* Uses explicit role-based messages (system, user, assistant).\n",
        "\n",
        "* Better for conversational AI, allowing structured interactions.\n",
        "\n",
        "* System message guides the AI‚Äôs behavior, making it more controllable."
      ],
      "metadata": {
        "id": "tKcZpYWhdw4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "# 'human', 'user', 'ai', 'assistant', or 'system'.  We can use this to set the role.\n",
        "messages = [\n",
        "    (\"system\", \"You are a helpful assistant that translates English to French.\"),\n",
        "    (\"user\", \"{message}\"),\n",
        "]\n",
        "prompt = ChatPromptTemplate.from_messages(messages)\n",
        "prompt.invoke({\"message\": \"I love programming.\"})\n",
        "\n",
        "# prompt.format_prompt(message=\"I love programming.\")\n",
        "# prompt.format_prompt(message=\"I love programming.\").to_messages()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hm7tHakd1gd",
        "outputId": "0e38db14-7c04-475e-c49c-3adb7e177fc7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant that translates English to French.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I love programming.', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Use of AIMessage, HumanMessage, SystemMessage (Structured Messages)**\n",
        "\n",
        "*  More structured (uses LangChain‚Äôs schema)\n",
        "\n",
        "*  Supports metadata (timestamps, sources, etc.)\n",
        "\n",
        "*  **Easier to integrate with memory, agents, and retrievers**\n",
        "\n",
        "*  Can differentiate between different AI/user messages easily"
      ],
      "metadata": {
        "id": "zLMekdANd9eV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant that translates English to French.\"),\n",
        "    HumanMessage(content=\"I love programming.\")\n",
        "]\n",
        "prompt = ChatPromptTemplate.from_messages(messages)\n",
        "prompt.invoke({})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hTi8pRpfeDfd",
        "outputId": "d0651144-9115-4fb5-94ca-0b690cfc559f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant that translates English to French.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I love programming.', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stoing History of conversatation"
      ],
      "metadata": {
        "id": "wUNILXOieHs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate , MessagesPlaceholder\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", \"You are a helpful assistant that translates English to French.\"),\n",
        "        (\"user\", \"{message}\"),\n",
        "        MessagesPlaceholder(variable_name=\"history\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt.invoke({\"message\": \"I love programming.\", \"history\": [\"Python\",\"C++\"]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXWu_qTMeHMF",
        "outputId": "432bb922-9302-4c2b-d666-1951a64755f7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant that translates English to French.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I love programming.', additional_kwargs={}, response_metadata={}), HumanMessage(content='Python', additional_kwargs={}, response_metadata={}), HumanMessage(content='C++', additional_kwargs={}, response_metadata={})])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Using PromptTemplate (Standard Prompt for LLMs)\n",
        "\n",
        "* Uses PromptTemplate, ideal for simple text completion models (like GPT-3).\n",
        "\n",
        "* No role-based structure (unlike ChatPromptTemplate).\n",
        "\n",
        "* Best for non-chat models."
      ],
      "metadata": {
        "id": "aMWt5nUHfltd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"product\"],\n",
        "    template=\"What is the best name for a company that makes {product}?\",\n",
        ")\n",
        "\n",
        "prompt.invoke({\"product\": \"colorful toy\"})\n",
        "# prompt.format(product=\"colorful toy\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxGsZ-Knfq3V",
        "outputId": "bc5a7b79-7d4d-4c74-8a7a-e9699cdcb164"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringPromptValue(text='What is the best name for a company that makes colorful toy?')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Using FewShotPromptTemplate (Few-shot Learning)\n",
        "\n",
        "* Best For: When you need to provide few-shot learning examples to guide the model."
      ],
      "metadata": {
        "id": "3m5-UFNQk-4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import FewShotPromptTemplate, PromptTemplate\n",
        "\n",
        "examples = [\n",
        "    {\"input\": \"Hello\", \"output\": \"Bonjour\"},\n",
        "    {\"input\": \"Goodbye\", \"output\": \"Au revoir\"},\n",
        "]\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"input\", \"output\"],\n",
        "    template=\"English: {input} -> French: {output}\"\n",
        ")\n",
        "\n",
        "few_shot_prompt = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=\"Translate the following English words to French:\",\n",
        "    suffix=\"English: {input} -> French:\",\n",
        "    input_variables=[\"input\"],\n",
        ")\n",
        "\n",
        "# print(few_shot_prompt.format(input=\"How are you?\"))\n",
        "few_shot_prompt.invoke({\"input\": \"How are you?\"})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l4cgxn0hlOF1",
        "outputId": "bad84a3e-4c59-4d97-9ecf-c175aa1a74b8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StringPromptValue(text='Translate the following English words to French:\\n\\nEnglish: Hello -> French: Bonjour\\n\\nEnglish: Goodbye -> French: Au revoir\\n\\nEnglish: How are you? -> French:')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ]
}